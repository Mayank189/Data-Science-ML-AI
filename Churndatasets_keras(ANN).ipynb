{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Churndatasets_keras(ANN).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p48npEK46KJ",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "fd304d50-69d7-4e00-9045-cb8b1808d569"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0efce8af-d53d-4755-9ea2-bbb5950b2ae0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0efce8af-d53d-4755-9ea2-bbb5950b2ae0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Churn_Modelling.csv to Churn_Modelling.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYvOM-SN8l0v"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRJNgd4u82-S"
      },
      "source": [
        "dataset=pd.read_csv(\"Churn_Modelling.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "VHRb364J9DQI",
        "outputId": "09eec039-09ad-42e1-b555-664aa5f9ad2b"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9996</td>\n",
              "      <td>15606229</td>\n",
              "      <td>Obijiaku</td>\n",
              "      <td>771</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9997</td>\n",
              "      <td>15569892</td>\n",
              "      <td>Johnstone</td>\n",
              "      <td>516</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9998</td>\n",
              "      <td>15584532</td>\n",
              "      <td>Liu</td>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9999</td>\n",
              "      <td>15682355</td>\n",
              "      <td>Sabbatini</td>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>10000</td>\n",
              "      <td>15628319</td>\n",
              "      <td>Walker</td>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      RowNumber  CustomerId    Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0             1    15634602   Hargrave  ...               1       101348.88      1\n",
              "1             2    15647311       Hill  ...               1       112542.58      0\n",
              "2             3    15619304       Onio  ...               0       113931.57      1\n",
              "3             4    15701354       Boni  ...               0        93826.63      0\n",
              "4             5    15737888   Mitchell  ...               1        79084.10      0\n",
              "...         ...         ...        ...  ...             ...             ...    ...\n",
              "9995       9996    15606229   Obijiaku  ...               0        96270.64      0\n",
              "9996       9997    15569892  Johnstone  ...               1       101699.77      0\n",
              "9997       9998    15584532        Liu  ...               1        42085.58      1\n",
              "9998       9999    15682355  Sabbatini  ...               0        92888.52      1\n",
              "9999      10000    15628319     Walker  ...               0        38190.78      0\n",
              "\n",
              "[10000 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nysGPf_09EwI"
      },
      "source": [
        "X=dataset.iloc[:,3:13]#independent features\n",
        "Y=dataset.iloc[:,13]#dependent features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJJ1aqlJ9hL-"
      },
      "source": [
        "#Create dummpies varibale\n",
        "geography=pd.get_dummies(X['Geography'],drop_first=True)\n",
        "gender=pd.get_dummies(X['Gender'],drop_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YQy5hT59i-q"
      },
      "source": [
        "#Concat the dataframe\n",
        "\n",
        "X=pd.concat([X,geography,gender],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiug93-C-ugU"
      },
      "source": [
        "#Drop uncessary column\n",
        "X=X.drop(['Geography','Gender'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJQQQFlp_VG-"
      },
      "source": [
        "#Splitting the datsets into training and test data sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3rd3uCf_y88"
      },
      "source": [
        "#Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3sWVkg6ATqH"
      },
      "source": [
        "#import keras libaries and package\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Embedding\n",
        "from keras.layers import LeakyReLU,PReLU,ELU\n",
        "from keras.layers import Dropout\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ1KH1ZROcdU"
      },
      "source": [
        "#Modifying the code(Should apply this section of code always)\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7xl60OGOeck"
      },
      "source": [
        "def create_model(layers,activation):\n",
        "  model=Sequential()\n",
        "  for i,nodes in enumerate(layers):\n",
        "    if i==0:\n",
        "      model.add(Dense(nodes,input_dim=X_train.shape[1]))\n",
        "      model.add(Activation(activation))\n",
        "      model.add(Dropout(0.3))\n",
        "    else:\n",
        "      model.add(Dense(nodes))\n",
        "      model.add(Activation(activation))\n",
        "      model.add(Dropout(0.3))\n",
        "  \n",
        "\n",
        "  model.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KAoKlN-Oe9M"
      },
      "source": [
        "model=KerasClassifier(build_fn=create_model,verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdskbc9LOe_8"
      },
      "source": [
        "#Hyperparameter Tunning using GridSearchCV\n",
        "layers=[[20],[40,20],[45,30,15]]\n",
        "activations=['sigmoid','relu']\n",
        "param_grid=dict(layers=layers,activation=activations,batch_size=[128,256],epochs=[30])\n",
        "grid=GridSearchCV(estimator=model,param_grid=param_grid,cv=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXhVYu4fOfCo"
      },
      "source": [
        "grid_result=grid.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRNw0LYBTA6v",
        "outputId": "0376d91d-9c39-41f3-9f5e-65c1821fd3ba"
      },
      "source": [
        "print(grid_result.best_score_,grid_result.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8547500014305115 {'activation': 'relu', 'batch_size': 128, 'epochs': 30, 'layers': [45, 30, 15]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjYhWZjMB89w"
      },
      "source": [
        "#Initializing the ANN\n",
        "classifier=Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeNKhP-5Dgmj"
      },
      "source": [
        "#Adding the input Layer and first hidden layer\n",
        "classifier.add(Dense(units=6,kernel_initializer='he_uniform',activation='relu',input_dim=11))\n",
        "classifier.add(Dropout(0.3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfxoHIhmDsPZ"
      },
      "source": [
        "#Adding the second hidden Layer\n",
        "classifier.add(Dense(units=6,kernel_initializer='he_uniform',activation='relu'))\n",
        "classifier.add(Dropout(0.4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKBb3z3vEa7o"
      },
      "source": [
        "#Adding the output layer\n",
        "classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nxwVu-BErHS",
        "outputId": "7e46b882-6578-41b9-d4cb-dcb17e180495"
      },
      "source": [
        "classifier.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 6)                 72        \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6)                 0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 121\n",
            "Trainable params: 121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqMGjaKRFZ6i"
      },
      "source": [
        "#Compiling the ANN\n",
        "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQs0N2JYF_FS",
        "outputId": "b17b884c-1e0a-4669-b8a9-4fb494d6881b"
      },
      "source": [
        "#Fitting the ANN to thr training set\n",
        "model_history=classifier.fit(X_train,Y_train,validation_split=0.33,batch_size=10,epochs= 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "536/536 [==============================] - 3s 2ms/step - loss: 0.8891 - accuracy: 0.5450 - val_loss: 0.5379 - val_accuracy: 0.7955\n",
            "Epoch 2/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5641 - accuracy: 0.7753 - val_loss: 0.4984 - val_accuracy: 0.7955\n",
            "Epoch 3/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5037 - accuracy: 0.7991 - val_loss: 0.4805 - val_accuracy: 0.7955\n",
            "Epoch 4/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5051 - accuracy: 0.7826 - val_loss: 0.4673 - val_accuracy: 0.7955\n",
            "Epoch 5/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.7912 - val_loss: 0.4618 - val_accuracy: 0.7955\n",
            "Epoch 6/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.7909 - val_loss: 0.4557 - val_accuracy: 0.7955\n",
            "Epoch 7/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4730 - accuracy: 0.7971 - val_loss: 0.4432 - val_accuracy: 0.7955\n",
            "Epoch 8/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4510 - accuracy: 0.8076 - val_loss: 0.4301 - val_accuracy: 0.7959\n",
            "Epoch 9/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.7955 - val_loss: 0.4281 - val_accuracy: 0.7955\n",
            "Epoch 10/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4494 - accuracy: 0.8085 - val_loss: 0.4262 - val_accuracy: 0.7948\n",
            "Epoch 11/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4440 - accuracy: 0.8059 - val_loss: 0.4205 - val_accuracy: 0.7982\n",
            "Epoch 12/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4472 - accuracy: 0.8042 - val_loss: 0.4212 - val_accuracy: 0.7955\n",
            "Epoch 13/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.8117 - val_loss: 0.4183 - val_accuracy: 0.7978\n",
            "Epoch 14/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4412 - accuracy: 0.8069 - val_loss: 0.4161 - val_accuracy: 0.7978\n",
            "Epoch 15/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4489 - accuracy: 0.8097 - val_loss: 0.4196 - val_accuracy: 0.7970\n",
            "Epoch 16/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4302 - accuracy: 0.8169 - val_loss: 0.4139 - val_accuracy: 0.8012\n",
            "Epoch 17/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4306 - accuracy: 0.8151 - val_loss: 0.4135 - val_accuracy: 0.8031\n",
            "Epoch 18/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4344 - accuracy: 0.8179 - val_loss: 0.4110 - val_accuracy: 0.8065\n",
            "Epoch 19/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4368 - accuracy: 0.8075 - val_loss: 0.4125 - val_accuracy: 0.8054\n",
            "Epoch 20/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4208 - accuracy: 0.8193 - val_loss: 0.4108 - val_accuracy: 0.8046\n",
            "Epoch 21/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4319 - accuracy: 0.8107 - val_loss: 0.4094 - val_accuracy: 0.8054\n",
            "Epoch 22/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4305 - accuracy: 0.8116 - val_loss: 0.4112 - val_accuracy: 0.8023\n",
            "Epoch 23/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4351 - accuracy: 0.8148 - val_loss: 0.4110 - val_accuracy: 0.8039\n",
            "Epoch 24/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4479 - accuracy: 0.8031 - val_loss: 0.4115 - val_accuracy: 0.8042\n",
            "Epoch 25/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4381 - accuracy: 0.8107 - val_loss: 0.4123 - val_accuracy: 0.8031\n",
            "Epoch 26/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4265 - accuracy: 0.8149 - val_loss: 0.4113 - val_accuracy: 0.8042\n",
            "Epoch 27/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4234 - accuracy: 0.8201 - val_loss: 0.4115 - val_accuracy: 0.8035\n",
            "Epoch 28/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4221 - accuracy: 0.8244 - val_loss: 0.4084 - val_accuracy: 0.8050\n",
            "Epoch 29/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4304 - accuracy: 0.8113 - val_loss: 0.4086 - val_accuracy: 0.8031\n",
            "Epoch 30/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4236 - accuracy: 0.8194 - val_loss: 0.4077 - val_accuracy: 0.8058\n",
            "Epoch 31/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4270 - accuracy: 0.8175 - val_loss: 0.4071 - val_accuracy: 0.8084\n",
            "Epoch 32/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4250 - accuracy: 0.8172 - val_loss: 0.4059 - val_accuracy: 0.8092\n",
            "Epoch 33/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4301 - accuracy: 0.8194 - val_loss: 0.4064 - val_accuracy: 0.8084\n",
            "Epoch 34/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4287 - accuracy: 0.8122 - val_loss: 0.4064 - val_accuracy: 0.8065\n",
            "Epoch 35/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4426 - accuracy: 0.8101 - val_loss: 0.4051 - val_accuracy: 0.8069\n",
            "Epoch 36/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4293 - accuracy: 0.8230 - val_loss: 0.4020 - val_accuracy: 0.8111\n",
            "Epoch 37/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4249 - accuracy: 0.8168 - val_loss: 0.4024 - val_accuracy: 0.8080\n",
            "Epoch 38/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4487 - accuracy: 0.8005 - val_loss: 0.3996 - val_accuracy: 0.8092\n",
            "Epoch 39/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4225 - accuracy: 0.8193 - val_loss: 0.3978 - val_accuracy: 0.8107\n",
            "Epoch 40/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4236 - accuracy: 0.8179 - val_loss: 0.3930 - val_accuracy: 0.8141\n",
            "Epoch 41/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4127 - accuracy: 0.8262 - val_loss: 0.3903 - val_accuracy: 0.8194\n",
            "Epoch 42/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4150 - accuracy: 0.8273 - val_loss: 0.3929 - val_accuracy: 0.8141\n",
            "Epoch 43/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4222 - accuracy: 0.8189 - val_loss: 0.3920 - val_accuracy: 0.8152\n",
            "Epoch 44/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4229 - accuracy: 0.8164 - val_loss: 0.3905 - val_accuracy: 0.8137\n",
            "Epoch 45/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4202 - accuracy: 0.8213 - val_loss: 0.3865 - val_accuracy: 0.8164\n",
            "Epoch 46/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4105 - accuracy: 0.8248 - val_loss: 0.3879 - val_accuracy: 0.8164\n",
            "Epoch 47/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4274 - accuracy: 0.8165 - val_loss: 0.3892 - val_accuracy: 0.8141\n",
            "Epoch 48/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4311 - accuracy: 0.8158 - val_loss: 0.3882 - val_accuracy: 0.8148\n",
            "Epoch 49/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4213 - accuracy: 0.8255 - val_loss: 0.3869 - val_accuracy: 0.8167\n",
            "Epoch 50/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4259 - accuracy: 0.8175 - val_loss: 0.3872 - val_accuracy: 0.8175\n",
            "Epoch 51/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3990 - accuracy: 0.8278 - val_loss: 0.3882 - val_accuracy: 0.8160\n",
            "Epoch 52/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4154 - accuracy: 0.8236 - val_loss: 0.3875 - val_accuracy: 0.8160\n",
            "Epoch 53/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4160 - accuracy: 0.8222 - val_loss: 0.3852 - val_accuracy: 0.8179\n",
            "Epoch 54/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4049 - accuracy: 0.8330 - val_loss: 0.3851 - val_accuracy: 0.8201\n",
            "Epoch 55/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4345 - accuracy: 0.8137 - val_loss: 0.3822 - val_accuracy: 0.8190\n",
            "Epoch 56/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4052 - accuracy: 0.8293 - val_loss: 0.3876 - val_accuracy: 0.8194\n",
            "Epoch 57/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4099 - accuracy: 0.8219 - val_loss: 0.3870 - val_accuracy: 0.8137\n",
            "Epoch 58/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4035 - accuracy: 0.8289 - val_loss: 0.3851 - val_accuracy: 0.8201\n",
            "Epoch 59/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4092 - accuracy: 0.8294 - val_loss: 0.3874 - val_accuracy: 0.8171\n",
            "Epoch 60/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4200 - accuracy: 0.8176 - val_loss: 0.3848 - val_accuracy: 0.8201\n",
            "Epoch 61/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4210 - accuracy: 0.8210 - val_loss: 0.3858 - val_accuracy: 0.8160\n",
            "Epoch 62/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4162 - accuracy: 0.8190 - val_loss: 0.3816 - val_accuracy: 0.8239\n",
            "Epoch 63/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4156 - accuracy: 0.8202 - val_loss: 0.3827 - val_accuracy: 0.8289\n",
            "Epoch 64/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4141 - accuracy: 0.8199 - val_loss: 0.3819 - val_accuracy: 0.8292\n",
            "Epoch 65/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4115 - accuracy: 0.8243 - val_loss: 0.3849 - val_accuracy: 0.8186\n",
            "Epoch 66/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4061 - accuracy: 0.8274 - val_loss: 0.3851 - val_accuracy: 0.8198\n",
            "Epoch 67/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4038 - accuracy: 0.8315 - val_loss: 0.3807 - val_accuracy: 0.8285\n",
            "Epoch 68/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3938 - accuracy: 0.8335 - val_loss: 0.3828 - val_accuracy: 0.8213\n",
            "Epoch 69/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4006 - accuracy: 0.8288 - val_loss: 0.3845 - val_accuracy: 0.8228\n",
            "Epoch 70/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4053 - accuracy: 0.8244 - val_loss: 0.3806 - val_accuracy: 0.8258\n",
            "Epoch 71/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4066 - accuracy: 0.8274 - val_loss: 0.3816 - val_accuracy: 0.8266\n",
            "Epoch 72/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3989 - accuracy: 0.8347 - val_loss: 0.3836 - val_accuracy: 0.8307\n",
            "Epoch 73/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4237 - accuracy: 0.8252 - val_loss: 0.3815 - val_accuracy: 0.8247\n",
            "Epoch 74/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4031 - accuracy: 0.8269 - val_loss: 0.3830 - val_accuracy: 0.8247\n",
            "Epoch 75/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4044 - accuracy: 0.8324 - val_loss: 0.3821 - val_accuracy: 0.8319\n",
            "Epoch 76/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4030 - accuracy: 0.8287 - val_loss: 0.3821 - val_accuracy: 0.8239\n",
            "Epoch 77/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4158 - accuracy: 0.8212 - val_loss: 0.3814 - val_accuracy: 0.8296\n",
            "Epoch 78/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4076 - accuracy: 0.8298 - val_loss: 0.3817 - val_accuracy: 0.8311\n",
            "Epoch 79/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4211 - accuracy: 0.8196 - val_loss: 0.3790 - val_accuracy: 0.8330\n",
            "Epoch 80/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3869 - accuracy: 0.8395 - val_loss: 0.3816 - val_accuracy: 0.8247\n",
            "Epoch 81/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4060 - accuracy: 0.8211 - val_loss: 0.3792 - val_accuracy: 0.8258\n",
            "Epoch 82/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4037 - accuracy: 0.8321 - val_loss: 0.3793 - val_accuracy: 0.8285\n",
            "Epoch 83/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4051 - accuracy: 0.8294 - val_loss: 0.3791 - val_accuracy: 0.8285\n",
            "Epoch 84/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4077 - accuracy: 0.8217 - val_loss: 0.3805 - val_accuracy: 0.8236\n",
            "Epoch 85/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4041 - accuracy: 0.8284 - val_loss: 0.3778 - val_accuracy: 0.8273\n",
            "Epoch 86/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4135 - accuracy: 0.8287 - val_loss: 0.3811 - val_accuracy: 0.8273\n",
            "Epoch 87/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4071 - accuracy: 0.8250 - val_loss: 0.3774 - val_accuracy: 0.8311\n",
            "Epoch 88/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4158 - accuracy: 0.8181 - val_loss: 0.3796 - val_accuracy: 0.8281\n",
            "Epoch 89/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3998 - accuracy: 0.8274 - val_loss: 0.3784 - val_accuracy: 0.8232\n",
            "Epoch 90/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4160 - accuracy: 0.8205 - val_loss: 0.3770 - val_accuracy: 0.8315\n",
            "Epoch 91/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4125 - accuracy: 0.8224 - val_loss: 0.3755 - val_accuracy: 0.8315\n",
            "Epoch 92/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4108 - accuracy: 0.8170 - val_loss: 0.3762 - val_accuracy: 0.8281\n",
            "Epoch 93/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4065 - accuracy: 0.8249 - val_loss: 0.3783 - val_accuracy: 0.8289\n",
            "Epoch 94/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4003 - accuracy: 0.8267 - val_loss: 0.3800 - val_accuracy: 0.8270\n",
            "Epoch 95/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4058 - accuracy: 0.8290 - val_loss: 0.3783 - val_accuracy: 0.8281\n",
            "Epoch 96/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.3969 - accuracy: 0.8338 - val_loss: 0.3797 - val_accuracy: 0.8300\n",
            "Epoch 97/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4087 - accuracy: 0.8267 - val_loss: 0.3794 - val_accuracy: 0.8262\n",
            "Epoch 98/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4203 - accuracy: 0.8144 - val_loss: 0.3785 - val_accuracy: 0.8277\n",
            "Epoch 99/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4021 - accuracy: 0.8270 - val_loss: 0.3810 - val_accuracy: 0.8228\n",
            "Epoch 100/100\n",
            "536/536 [==============================] - 1s 2ms/step - loss: 0.4070 - accuracy: 0.8225 - val_loss: 0.3805 - val_accuracy: 0.8220\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJJBTQ0RKB67"
      },
      "source": [
        "#predicting the test result sets\n",
        "y_pred=classifier.predict(X_test)\n",
        "y_pred=(y_pred>0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5Y-AcAbKbs1"
      },
      "source": [
        "#Making the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm=confusion_matrix(Y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak2tjktxKzyX"
      },
      "source": [
        "#Calculate the accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "score=accuracy_score(Y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}